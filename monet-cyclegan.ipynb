{"cells":[{"metadata":{"execution":{"iopub.execute_input":"2020-12-12T16:36:30.170567Z","iopub.status.busy":"2020-12-12T16:36:30.169698Z","iopub.status.idle":"2020-12-12T16:36:58.984219Z","shell.execute_reply":"2020-12-12T16:36:58.984822Z"},"papermill":{"duration":28.840048,"end_time":"2020-12-12T16:36:58.985045","exception":false,"start_time":"2020-12-12T16:36:30.144997","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"!pip install tensorflow-addons==0.9.1 ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-12-12T16:36:59.034018Z","iopub.status.busy":"2020-12-12T16:36:59.033204Z","iopub.status.idle":"2020-12-12T16:37:04.928083Z","shell.execute_reply":"2020-12-12T16:37:04.927328Z"},"papermill":{"duration":5.924139,"end_time":"2020-12-12T16:37:04.928214","exception":false,"start_time":"2020-12-12T16:36:59.004075","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport IPython.display as display\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\nimport random\nimport math\n\nimport time\nfrom IPython.display import clear_output","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-12T16:37:05.015372Z","iopub.status.busy":"2020-12-12T16:37:05.014468Z","iopub.status.idle":"2020-12-12T16:37:09.25782Z","shell.execute_reply":"2020-12-12T16:37:09.25846Z"},"papermill":{"duration":4.312812,"end_time":"2020-12-12T16:37:09.258775","exception":false,"start_time":"2020-12-12T16:37:04.945963","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.MirroredStrategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-12-12T16:37:09.307707Z","iopub.status.busy":"2020-12-12T16:37:09.306448Z","iopub.status.idle":"2020-12-12T16:37:09.977926Z","shell.execute_reply":"2020-12-12T16:37:09.977054Z"},"papermill":{"duration":0.698753,"end_time":"2020-12-12T16:37:09.978062","exception":false,"start_time":"2020-12-12T16:37:09.279309","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\nGCS_PATH = KaggleDatasets().get_gcs_path()\n\nMONET_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/monet_tfrec/*.tfrec'))\nprint('Monet TFRecord Files:', len(MONET_FILENAMES))\n\nPHOTO_FILENAMES = tf.io.gfile.glob(str(GCS_PATH + '/photo_tfrec/*.tfrec'))\nprint('Photo TFRecord Files:', len(PHOTO_FILENAMES))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-12T16:37:10.033509Z","iopub.status.busy":"2020-12-12T16:37:10.032719Z","iopub.status.idle":"2020-12-12T16:37:10.036409Z","shell.execute_reply":"2020-12-12T16:37:10.035779Z"},"papermill":{"duration":0.038461,"end_time":"2020-12-12T16:37:10.036567","exception":false,"start_time":"2020-12-12T16:37:09.998106","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = [256, 256]\n\ndef decode_image(image):\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = (tf.cast(image, tf.float32) / 127.5) - 1\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    return image\n\ndef random_crop(image):\n    cropped_image = tf.image.random_crop(\n    image, size=[*IMAGE_SIZE, 3])\n\n    return cropped_image\n\ndef random_jitter(image):\n    # resizing to 286 x 286 x 3\n    image = tf.image.resize(image, [286, 286],\n                          method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n\n    # randomly cropping to 256 x 256 x 3\n    image = random_crop(image)\n\n    # random mirroring\n    image = tf.image.random_flip_left_right(image)\n\n    return image\n\ndef read_tfrecord(example):\n    tfrecord_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    example = tf.io.parse_single_example(example, tfrecord_format)\n    image = decode_image(example['image'])\n    return image\n\ndef load_dataset(filenames, labeled=True, ordered=False):\n    dataset = tf.data.TFRecordDataset(filenames)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-12T16:37:10.087976Z","iopub.status.busy":"2020-12-12T16:37:10.086762Z","iopub.status.idle":"2020-12-12T16:37:10.429121Z","shell.execute_reply":"2020-12-12T16:37:10.428382Z"},"papermill":{"duration":0.37327,"end_time":"2020-12-12T16:37:10.429258","exception":false,"start_time":"2020-12-12T16:37:10.055988","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\n\nsubmit_ds = load_dataset(PHOTO_FILENAMES, labeled=True).batch(1)\n\nmonet_ds = load_dataset(MONET_FILENAMES, labeled=True).map(random_jitter, num_parallel_calls=AUTOTUNE).shuffle(300).batch(1)\nphoto_ds = load_dataset(PHOTO_FILENAMES, labeled=True).map(random_jitter, num_parallel_calls=AUTOTUNE).shuffle(300).batch(1)\n\nfinal_dataset = tf.data.Dataset.zip((monet_ds, photo_ds))","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-12T16:37:10.477456Z","iopub.status.busy":"2020-12-12T16:37:10.476689Z","iopub.status.idle":"2020-12-12T16:37:10.987195Z","shell.execute_reply":"2020-12-12T16:37:10.986009Z"},"papermill":{"duration":0.537776,"end_time":"2020-12-12T16:37:10.987397","exception":false,"start_time":"2020-12-12T16:37:10.449621","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"it = iter(submit_ds)\ntes = next(it)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_images(model, test_input):\n  prediction = model(test_input)\n\n  plt.figure(figsize=(12, 12))\n\n  display_list = [test_input[0], prediction[0]]\n  title = ['Input Image', 'Predicted Image']\n\n  for i in range(2):\n    plt.subplot(1, 2, i+1)\n    plt.title(title[i])\n    # getting the pixel values between [0, 1] to plot it.\n    plt.imshow(display_list[i] * 0.5 + 0.5)\n    plt.axis('off')\n  plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ReflectionPadding2D(tf.keras.layers.Layer):\n    def __init__(self, padding=(1, 1), **kwargs):\n        self.padding = tuple(padding)\n        self.input_spec = [tf.keras.layers.InputSpec(ndim=4)]\n        super(ReflectionPadding2D, self).__init__(**kwargs)\n\n    def compute_output_shape(self, s):\n        \"\"\" If you are using \"channels_last\" configuration\"\"\"\n        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n\n    def call(self, x, mask=None):\n        w_pad,h_pad = self.padding\n        return tf.pad(x, [[0,0], [h_pad,h_pad], [w_pad,w_pad], [0,0] ], 'REFLECT')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def FeatureMapBlock(output_channels):\n    initializer = tf.random_normal_initializer(0.,0.02)\n    \n    result = tf.keras.Sequential()\n    \n    result.add(ReflectionPadding2D((3,3)))\n    result.add(tf.keras.layers.Conv2D(\n                                output_channels, \n                                7, \n                                strides= 1, \n                                kernel_initializer=initializer,\n                                use_bias=False,\n                                padding='valid'\n               ))\n    \n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ContractingBlock(output_channels, use_bn=True, kernel_size=3, strides=2, activation='relu'):\n    #Intializer\n    initializer = tf.random_normal_initializer(0.,0.02)\n    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.02)\n    \n    #Layers\n    result = tf.keras.Sequential()\n    \n    result.add(ReflectionPadding2D((1,1)))\n    \n    result.add(tf.keras.layers.Conv2D(output_channels, \n                                           kernel_size= kernel_size, \n                                           kernel_initializer=initializer,\n                                           use_bias=False,\n                                           strides= strides, \n                                           padding='valid'))\n    \n    if use_bn:\n            result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n    \n    if activation == 'lrelu':\n        result.add(tf.keras.layers.LeakyReLU(0.2))\n    elif activation == 'relu':\n        result.add(tf.keras.layers.Activation('relu'))\n    else:\n        result.add(tf.keras.layers.Activation('sigmoid'))\n    \n    return result   ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-12T16:37:11.161443Z","iopub.status.busy":"2020-12-12T16:37:11.160588Z","iopub.status.idle":"2020-12-12T16:37:11.164182Z","shell.execute_reply":"2020-12-12T16:37:11.163381Z"},"papermill":{"duration":0.037192,"end_time":"2020-12-12T16:37:11.16431","exception":false,"start_time":"2020-12-12T16:37:11.127118","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class ResidualBlock(tf.keras.Model):\n\n    def __init__(self, output_channels):\n        super(ResidualBlock, self).__init__()\n        \n        #Initializer\n        initializer = tf.random_normal_initializer(0.,0.02)\n        gamma_init = tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.02)\n        \n        #Layer\n        self.padding1 = ReflectionPadding2D((1,1))\n        self.padding2 = ReflectionPadding2D((1,1))\n        \n        \n        self.conv1 = tf.keras.layers.Conv2D(output_channels, \n                                            3, \n                                            padding='valid', \n                                            kernel_initializer=initializer,\n                                            use_bias=False,)\n        \n        self.conv2 = tf.keras.layers.Conv2D(output_channels, \n                                            3, \n                                            padding='valid', \n                                            kernel_initializer=initializer,\n                                            use_bias=False,)\n        \n        \n        self.instancenorm1 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)\n        self.instancenorm2 = tfa.layers.InstanceNormalization(gamma_initializer=gamma_init)\n        self.activation = tf.keras.layers.Activation('relu')\n\n    def call(self, x):\n    \n        x_original = tf.identity(x)\n        x = self.padding1(x)\n        x = self.conv1(x)\n        x = self.instancenorm1(x)\n        x = self.activation(x)\n        x = self.padding2(x)\n        x = self.conv2(x)\n        x = self.instancenorm2(x)\n    \n        return (x_original + x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def ExpandingBlock(output_channels, use_bn=True, kernel_size=3):\n    #Intializer\n    initializer = tf.random_normal_initializer(0.,0.02)\n    gamma_init = tf.keras.initializers.RandomNormal(mean=0.0,stddev=0.02)\n    \n    #Layers\n    result = tf.keras.Sequential()\n    \n    result.add(tf.keras.layers.UpSampling2D(size=(2, 2), interpolation='nearest'))\n    \n    result.add(ReflectionPadding2D((1,1)))\n    \n    result.add(tf.keras.layers.Conv2D(output_channels, \n                                      kernel_size= kernel_size, \n                                      kernel_initializer=initializer,\n                                      use_bias=False,\n                                      strides= 1, \n                                      padding='valid'))\n    \n    if use_bn:\n        result.add(tfa.layers.InstanceNormalization(gamma_initializer=gamma_init))\n    \n    result.add(tf.keras.layers.Activation('relu'))\n    \n    return result   ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-12T16:37:11.278417Z","iopub.status.busy":"2020-12-12T16:37:11.277514Z","iopub.status.idle":"2020-12-12T16:37:11.281308Z","shell.execute_reply":"2020-12-12T16:37:11.280481Z"},"papermill":{"duration":0.038365,"end_time":"2020-12-12T16:37:11.281443","exception":false,"start_time":"2020-12-12T16:37:11.243078","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class Generator(tf.keras.Model):\n\n    def __init__(self, output_channels=3, res_layer= 9, hidden_channels=64):\n        super(Generator, self).__init__()\n        self.upfeature = FeatureMapBlock(hidden_channels)\n        self.contract1 = ContractingBlock(hidden_channels*2)\n        self.contract2 = ContractingBlock(hidden_channels * 4)\n        self.res = [ResidualBlock(hidden_channels * 4) for _ in range(res_layer)]\n        self.expand2 = ExpandingBlock(hidden_channels * 2)\n        self.expand3 = ExpandingBlock(hidden_channels)\n        self.downfeature = FeatureMapBlock(output_channels)\n        self.tanh = tf.keras.layers.Activation('tanh')\n        \n    def call(self, x):\n        \n        x = self.upfeature(x)\n        x = self.contract1(x)\n        x = self.contract2(x)\n        for layer in self.res:\n            x = layer(x)\n        x = self.expand2(x)\n        x = self.expand3(x)\n        x = self.downfeature(x)\n        \n        return self.tanh(x)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-12T16:37:11.337217Z","iopub.status.busy":"2020-12-12T16:37:11.336082Z","iopub.status.idle":"2020-12-12T16:37:11.339822Z","shell.execute_reply":"2020-12-12T16:37:11.339157Z"},"papermill":{"duration":0.037639,"end_time":"2020-12-12T16:37:11.339951","exception":false,"start_time":"2020-12-12T16:37:11.302312","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"class Discriminator(tf.keras.Model):\n    \n    \n    def __init__(self, hidden_channels=64):\n        super(Discriminator, self).__init__()\n        \n        # initializer\n        initializer = tf.random_normal_initializer(0.,0.02)\n        \n        self.contract1 = ContractingBlock(hidden_channels, use_bn=False, kernel_size=4, activation='lrelu')\n        self.contract2 = ContractingBlock(hidden_channels*2, kernel_size=4, activation='lrelu')\n        self.contract3 = ContractingBlock(hidden_channels*4, kernel_size=4, activation='lrelu')\n        self.contract4 = ContractingBlock(hidden_channels*8, kernel_size=4, strides=1, activation='lrelu')\n        self.final = ContractingBlock(1, kernel_size=4, use_bn=False, strides=1, activation='sigmoid')\n\n    def call(self, x):\n        x = self.contract1(x)\n        x = self.contract2(x)\n        x = self.contract3(x)\n        x = self.contract4(x)\n        x = self.final(x)\n        return x","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-12T16:37:11.390944Z","iopub.status.busy":"2020-12-12T16:37:11.390097Z","iopub.status.idle":"2020-12-12T16:37:11.568836Z","shell.execute_reply":"2020-12-12T16:37:11.568119Z"},"papermill":{"duration":0.20821,"end_time":"2020-12-12T16:37:11.568966","exception":false,"start_time":"2020-12-12T16:37:11.360756","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    g_monet = Generator()\n    g_photo = Generator()\n    \n    d_monet = Discriminator()\n    d_photo = Discriminator()\n    \n    g_monet_optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5)\n    g_photo_optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5)\n    d_monet_optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5)\n    d_photo_optimizer = tf.keras.optimizers.Adam(0.0002, beta_1=0.5)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-12T16:37:11.62334Z","iopub.status.busy":"2020-12-12T16:37:11.619648Z","iopub.status.idle":"2020-12-12T16:37:11.627405Z","shell.execute_reply":"2020-12-12T16:37:11.62658Z"},"papermill":{"duration":0.037667,"end_time":"2020-12-12T16:37:11.627563","exception":false,"start_time":"2020-12-12T16:37:11.589896","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#adv_criterion = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.SUM)\n#recon_criterion = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.SUM)\n\nwith strategy.scope():\n    def adv_criterion(x,y):\n        return tf.reduce_mean(tf.math.squared_difference(x,y))\n    \n    def recon_criterion(x,y):\n        return tf.reduce_mean(tf.abs(x-y))\n    \n    def get_disc_loss(d_fake, d_real, adv_criterion):\n        return 0.5 * adv_criterion(d_real, tf.ones_like(d_real)) + 0.5 * adv_criterion(d_fake, tf.zeros_like(d_fake)) \n    \n    def get_gen_loss(d_fake, adv_criterion):\n        return 0.5*adv_criterion(d_fake, tf.ones_like(d_fake))\n    \n    def get_identity_loss(real, identity, identity_criterion, lambda_identity):\n        return lambda_identity * identity_criterion(real, identity)\n    \n    def get_cycle_consistency_loss(real, cycle, cycle_criterion, lambda_cycle):\n        return lambda_cycle * cycle_criterion(real, cycle)\n    \n   \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CycleGan(tf.keras.Model):\n    def __init__(\n                self,\n                monet_generator,\n                photo_generator,\n                monet_discriminator,\n                photo_discriminator\n        ):\n        super(CycleGan, self).__init__()\n        self.g_monet = g_monet\n        self.g_photo = g_photo\n        self.d_monet = d_monet\n        self.d_photo = d_photo\n        \n    def compile(\n        self,\n        m_gen_optimizer,\n        p_gen_optimizer,\n        m_disc_optimizer,\n        p_disc_optimizer,\n        disc_loss_fn,\n        gen_loss_fn,\n        cycle_loss_fn,\n        identity_loss_fn\n    ):\n        super(CycleGan, self).compile()\n        self.g_monet_optimizer = m_gen_optimizer\n        self.g_photo_optimizer = p_gen_optimizer\n        self.d_monet_optimizer = m_disc_optimizer\n        self.d_photo_optimizer = p_disc_optimizer\n        self.get_disc_loss = disc_loss_fn\n        self.get_gen_loss = gen_loss_fn\n        self.get_cycle_loss = cycle_loss_fn\n        self.get_identity_loss = identity_loss_fn\n     \n    def train_step(self, batch_data):\n        real_monet, real_photo = batch_data\n        \n        with tf.GradientTape(persistent=True) as tape:\n            fake_monet = self.g_monet(real_photo, training=True)\n            fake_photo = self.g_photo(real_monet, training=True)\n            \n            identity_monet = self.g_monet(real_monet, training=True)\n            identity_photo = self.g_photo(real_photo, training=True)\n            \n            cycle_monet = self.g_monet(fake_photo, training=True)\n            cycle_photo = self.g_photo(fake_monet, training=True)\n            \n            d_fake_monet = self.d_monet(fake_monet, training=True)\n            d_fake_photo = self.d_photo(fake_photo, training=True)\n            \n            d_real_monet = self.d_monet(real_monet, training=True)\n            d_real_photo = self.d_photo(real_photo, training=True)\n            \n            #Calculate Adversarial Loss of Monet Discrimator, the Gradient and train the Discrimintaor\n            monet_disc_loss = self.get_disc_loss(d_fake_monet, d_real_monet, adv_criterion)\n            \n            #Calculate Adversarial Loss of Photo Discrimator, the Gradient and train the Discrimintaor\n            photo_disc_loss = self.get_disc_loss(d_fake_photo, d_real_photo, adv_criterion)\n            \n            #Calculate Generator Loss, Total Cycle Loss, and Identity Loss\n            total_cycle_loss = (self.get_cycle_loss(real_monet, cycle_monet, recon_criterion, 10) +\n                                self.get_cycle_loss(real_photo, cycle_photo, recon_criterion, 10))\n            \n            monet_gen_loss = self.get_gen_loss(d_fake_monet, adv_criterion)\n            photo_gen_loss = self.get_gen_loss(d_fake_photo, adv_criterion)\n            \n            monet_identity_loss = self.get_identity_loss(real_monet, identity_monet, recon_criterion, 5)\n            photo_identity_loss = self.get_identity_loss(real_photo, identity_photo, recon_criterion, 5)\n            \n            monet_total_gen_loss = monet_gen_loss + total_cycle_loss + monet_identity_loss\n \n            photo_total_gen_loss = photo_gen_loss + total_cycle_loss + photo_identity_loss\n            \n        monet_disc_gradients = tape.gradient(monet_disc_loss, self.d_monet.trainable_variables)\n        self.d_monet_optimizer.apply_gradients(zip(monet_disc_gradients, self.d_monet.trainable_variables))    \n        \n        photo_disc_gradients = tape.gradient(photo_disc_loss, self.d_photo.trainable_variables)\n        self.d_photo_optimizer.apply_gradients(zip(photo_disc_gradients, self.d_photo.trainable_variables))\n        \n        monet_gen_gradients = tape.gradient(monet_total_gen_loss, self.g_monet.trainable_variables)\n        self.g_monet_optimizer.apply_gradients(zip(monet_gen_gradients, self.g_monet.trainable_variables))\n        \n        photo_gen_gradients = tape.gradient(photo_total_gen_loss, self.g_photo.trainable_variables)\n        self.g_photo_optimizer.apply_gradients(zip(photo_gen_gradients, self.g_photo.trainable_variables))\n            \n        return {\n            \"monet_gen_loss\": monet_total_gen_loss,\n            \"photo_gen_loss\": photo_total_gen_loss,\n            \"monet_disc_loss\": monet_disc_loss,\n            \"photo_disc_loss\": photo_disc_loss\n        } ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs=None):\n        clear_output(wait=True)\n        generate_images(g_monet, tes) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    cycle_gan = CycleGan(\n                    g_monet,\n                    g_photo,\n                    d_monet,\n                    d_photo\n    )\n    cycle_gan.compile(\n                    g_monet_optimizer,\n                    g_photo_optimizer,\n                    d_monet_optimizer,\n                    d_photo_optimizer,\n                    get_disc_loss,\n                    get_gen_loss,\n                    get_cycle_consistency_loss,\n                    get_identity_loss\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = cycle_gan.fit(\n    final_dataset,\n    epochs=,\n    callbacks=[CustomCallback()]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cycle_gan.d_photo.save('./d_photo',save_format='tf')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\nshutil.make_archive(\"/kaggle/working/g_photo\", 'zip', \"/kaggle/working\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run the trained model on the test dataset\nfor inp in submit_ds.take(20):\n  generate_images(g_monet, inp)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-12T17:45:35.678076Z","iopub.status.busy":"2020-12-12T17:45:35.677265Z","iopub.status.idle":"2020-12-12T18:27:10.91644Z","shell.execute_reply":"2020-12-12T18:27:10.91566Z"},"papermill":{"duration":2507.692187,"end_time":"2020-12-12T18:27:10.916673","exception":false,"start_time":"2020-12-12T17:45:23.224486","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import PIL\n! mkdir ./images\ni = 1\nfor img in submit_ds:\n    prediction = g_monet(img, training=False)[0].numpy()\n    prediction = (prediction * 127.5 + 127.5).astype(np.uint8)\n    im = PIL.Image.fromarray(prediction)\n    im.save(\"./images/\" + str(i) + \".jpg\")\n    i += 1","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-12T18:27:36.086074Z","iopub.status.busy":"2020-12-12T18:27:36.085162Z","iopub.status.idle":"2020-12-12T18:27:41.202676Z","shell.execute_reply":"2020-12-12T18:27:41.201712Z"},"papermill":{"duration":17.818885,"end_time":"2020-12-12T18:27:41.202858","exception":false,"start_time":"2020-12-12T18:27:23.383973","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import shutil\nshutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/working\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}